\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\Ex}{\mathbb{E}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\mean}{\mu}
\newcommand{\naturals}{\mathbb{N}}

\newcommand{\one}{\mathbbm{1}}
\newcommand{\actionValueEstimate}{$\mathcal{E}$}
\newcommand{\epsilonFunction}{$\varepsilon(t)$}
\newcommand{\gap}[1]{\Delta_{#1}}

\newcommand{\numArms}{K}
\newcommand{\armsList}{A}
\newcommand{\timeHorizon}{T}
\newcommand{\armDistribution}[1]{\mathrm{P}_{#1}}
\newcommand{\maxArmDistribution}{\armDistribution{\star}}
\newcommand{\armPopulationMean}[1]{\mean_{#1}}
\newcommand{\maxPopulationMean}{\armPopulationMean{\star}}
\newcommand{\armDistributionVect}{\mathrm{P}}
\newcommand{\banditSpace}{\xi}
\newcommand{\aBandit}{\mean}

\newcommand{\aDifBandit}{\bar{\mean}}
\newcommand{\vectorBanditMeans}{\hat{\mean}}

\newcommand{\totalFunction}[2]{\mathbb{T}_{#1}(#2)}
\newcommand{\ucb}[3]{\mathrm{UCB}_{#1}^{#3}(#2)}
\newcommand{\ucbPolicy}{\policy_{\mathrm{UCB}}}

\newcommand{\empiricalMeanReward}[2]{\hat{\mean}_{#1}(#2)}
\newcommand{\maxMeanArm}[1]{\mathrm{M}(#1)}

\newcommand{\failureProb}{\delta}
\newcommand{\stoppingTime}{\mathcal{T}}
\newcommand{\selectionRule}{\mathcal{S}}
\newcommand{\method}{\mathcal{M}}

\newcommand{\action}[1]{A_{#1}}

\newcommand{\reward}[2]{
   \ifthenelse{\isempty{#2}}{
   Y_{#1}(\action{#1})}{
   Y_{#1}(#2)}}

\newcommand{\policy}{\varphi}

\newcommand{\cumulativeRegret}[2]{\mathcal{R}_{#1}(#2)}
\newcommand{\simpleRegret}[2]{\mathcal{R}_{#1}(#2)}

\newcommand{\commented}[1]{}

\newcommand{\seperator}[0]{\centerline{\rule{0.5\textwidth}{0.4pt}}}